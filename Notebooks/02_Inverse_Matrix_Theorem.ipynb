{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The inverse Matrix Theorem\n",
    "\n",
    "The inverse matrix theorem is a statement about a number of equivalent conditions that we can impose on a matrix.\n",
    "\n",
    "Given a matrix $A$ with shape $(n, n)$\n",
    "1.  $Det(A) \\neq 0$ implies $A^{-1}$ exists.\n",
    "2.  We can find a Matrix B such that $A * B = B * A = np.eye(n) = I_n$\n",
    "3.  $Det(A) = \\lambda _1 * \\lambda _2 * ... * \\lambda _n$ where $\\lambda _i$ is an eigenvalue of the matrix.\n",
    "\n",
    "These require some explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinants.\n",
    "\n",
    "Linear Transformations may stretch the underlying space by some magnitude (eigenvalues) along certain vectors (eigenvectors).  These are the vectors and values which \"characterize a matrix.\" -- Hence the word eigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "Determinant is: -2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "A = np.array(range(1,5)).reshape(2,2)\n",
    "determinant_A = la.det(A)\n",
    "\n",
    "print(A)\n",
    "print(\"Determinant is: {}\".format(determinant_A)) # Notice the rounding error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.... is this related to anything??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Matrix A has eigenvalues: [-0.37228132326901431, 5.3722813232690143]\n",
      "And their product is: -1.9999999999999998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check it's eigenvalues.\n",
    "print(\"The Matrix A has eigenvalues: {}\".format([x for x in la.eigvals(A)]))\n",
    "print(\"And their product is: {}\".format(np.product(la.eigvals(A))))\n",
    "determinant_A - np.product(la.eigvals(A)) < 10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define an epsilon and check if they are the same.\n",
    "eps = 10 ** -5\n",
    "def check_floats_equal(float_1, float_2, eps=eps):\n",
    "    return float_1 - float_2 < eps\n",
    "\n",
    "check_floats_equal(np.product(la.eigvals(A)), la.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... Interesting.\n",
    "\n",
    "The Determinant of a matrix is just the product of it's eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.82456484 -0.41597356]\n",
      " [ 0.56576746 -0.90937671]]\n"
     ]
    }
   ],
   "source": [
    "vals, vecs = la.eig(A)\n",
    "print(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define a distance function for vectors in a matrix.\n",
    "def l2_distance_cols(matrix):\n",
    "    norms = []\n",
    "    for row in matrix.transpose():\n",
    "        dist = 0\n",
    "        for val in row:\n",
    "            dist += val ** 2\n",
    "        \n",
    "        norms.append(dist)\n",
    "    \n",
    "    return np.array(norms)\n",
    "        \n",
    "l2_distance_cols(vecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the eigenvectors are normalized to length 1.\n",
    "\n",
    "Let's look at another matrix and look at its eigenvalues and eigenvectors.  This one should be a bit simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([0, -1, 1, 0]).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1],\n",
       "       [ 1,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values:\n",
      "[ 0.+1.j  0.-1.j]\n",
      "Vectors:\n",
      "[[ 0.70710678+0.j          0.70710678-0.j        ]\n",
      " [ 0.00000000-0.70710678j  0.00000000+0.70710678j]]\n"
     ]
    }
   ],
   "source": [
    "vals, vecs = np.linalg.eig(A)\n",
    "print(\"Values:\\n{}\".format(vals))\n",
    "print(\"Vectors:\\n{}\".format(vecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.... what is happening there, why does it have imaginary eigenvectors??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First a quick vector making helper function.\n",
    "def list_to_vector(items):\n",
    "    return np.array(items).reshape(len(items), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A, list_to_vector([1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [ 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A, list_to_vector([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a twist to me.  It's sending \n",
    "$$ [1, 0]^T \\mapsto [0,1]^T$$\n",
    "$$ [0, 1]^T \\mapsto [-1,0]^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it's a twist... how can it have a direction it stretches something in a straight line in... we'd have to imagine really hard...\n",
    "\n",
    "Oh.\n",
    "\n",
    "That's why it has imaginary eigenvectors -- they don't ``really`` exist.  But they do symbolically and mathematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... according to the inverse matrix theorem, the fact that $Det(A) = 1 \\neq 0$ implies that it has an inverse matrix.  Lets check that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is A^-1\n",
      "[[ 0.  1.]\n",
      " [-1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(\"Here is A^-1\\n{}\".format(A_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A_inv, list_to_vector([1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A_inv, list_to_vector([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm...\n",
    "\n",
    "$$ [1,0]^T \\mapsto [0,-1]^T \\\\ [0,1]^T \\mapsto [1,0]^T $$\n",
    "\n",
    "Oh!\n",
    "\n",
    "It's a rotation in the opposite direction!!  Neato gang!\n",
    "\n",
    "What happens if we multiply the two together...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1]\n",
      " [ 1  0]] \n",
      "* \n",
      "[[ 0.  1.]\n",
      " [-1.  0.]] \n",
      "=\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "I_2 = np.matmul(A, A_inv)\n",
    "print(\"{} \\n* \\n{} \\n=\\n{}\".format(A, A_inv, I_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just get the identity matrix back -- just like we wanted!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take another example.\n",
    "\n",
    "Fix a new matrix $A = 2 * I_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.]\n",
      " [ 0.  2.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.eye(2) * 2\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vals:\n",
      "[ 2.  2.]\n",
      "Vecs:\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "vals, vecs = np.linalg.eig(A)\n",
    "print(\"Vals:\\n{}\".format(vals))\n",
    "print(\"Vecs:\\n{}\".format(vecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should the inverse of $A$ be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inverse is:\n",
      "[[ 0.5  0. ]\n",
      " [ 0.   0.5]]\n"
     ]
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(\"The inverse is:\\n{}\".format(A_inv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... We have \n",
    "$$A = 2 * I_2$$\n",
    "$$A^{-1} = \\frac{1}{2} * I_2$$\n",
    "\n",
    "It looks like it just stretches along the eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
